● gfarm 全体に関わる問題点

- gfarm_agent は、現在のところユーザ認証を行なっていません。

  gfarm_agent はメタデータの読み書きを行ないます。従ってこれは、
  gfarm_agent にネットワーク的に到達可能であれば、誰でも、どんな
  メタデータでも変更できてしまうことを意味します。

  対処予定:
	gfarm v2 にはこの問題はありません。gfarm_agent に対応する機能を
	gfmd が受け持つためです。
	gfarm v1 での対処は未定です。

- ファイル関係のメタデータに関して、ユーザ単位の保護機能がありません。

  gfarm ユーザであれば、誰でも、どんなファイルやディレクトリの
  メタデータでも変更できてしまいます。

  対処予定:
	gfarm v2 の最初のリリースで対処します。
	gfarm v1 での対処の予定はありません。

- ホスト関係のメタデータに関して、ユーザ単位の保護機能がありません。

  gfarm ユーザであれば、誰でも、どのホストに関するメタデータでも
  変更できてしまいます。

  対処予定: 
	gfarm v2 の最初のリリースで対処します。
	gfarm v1 の場合でも、メタデータを保持する LDAP サーバないし
	PostgreSQL サーバの設定を行なうだけでこの対処はできます。
	ただし、今のところ config-gfarm が自動で行なう設定にはこの
	対処は含まれていませんし、また、手動の設定は可能なものの、
	ドキュメントが存在しません。

- ファイルアクセス権限の検査が完全ではありません。

  たとえば、ファイル作成時の権限検査において、そのファイルの存在する
  ディレクトリの書き込み権限は検査しますが、そのファイルの祖先のディレクトリの
  「x」ビットは検査していません。このため、本来ならアクセス拒否されるはずの
  ディレクトリにファイルを作成できてしまうことがあります。
  逆に、ファイルの作成を試みる場合、対象のファイルが既に存在するならば、
  そのファイルの親ディレクトリへの書き込み権限がなくても、本来ならオープン
  できる筈です。しかし現在の実装では、アクセス拒否されてしまいます。

  対処予定:
	gfarm v2 の最初のリリースで対処します。
	gfarm v1 での対処は未定です。

- gfarm スプール中の、ディレクトリ権限設定に問題があります。

  ファイルシステムノードに存在するスプール中の実ディレクトリは、ファイル
  新規作成やレプリカ作成時に、必要に応じて作られます。
  この実ディレクトリの所有者は、実ディレクトリ作成のきっかけとなる
  処理 (ファイル新規作成やレプリカ作成) を実施したユーザとなってしまい、
  必ずしも本来の所有者になりません。
  また、そのような場合、実ディレクトリのモードも、本来のモードではなく
  0777、すなわち誰でも読み書き可能なモードとなってしまいます。
  従って、このような場合、スプールに直接アクセスすると、ディレクトリ
  権限によるアクセス保護をバイパスすることができてしまいます。

  対処予定:
	gfarm v2 では、スプールの構造上、この問題はありません。
	gfarm v1 での対処は未定です。

- レプリカ作成時の、スプール中のファイル権限設定に問題があります。

  レプリカ作成を行なった場合、そのレプリカに対応するスプール中の
  実ファイルの所有者は、レプリカ作成を実施したユーザとなります。
  このため、本来の所有者とは異なる所有者になることがあります。
  また、そのような場合、実ファイルのモードも、本来のモードではなく
  0777、すなわち誰でも読み書き可能なモードとなってしまいます。
  従って、このような場合、スプールに直接アクセスすると、ファイル
  アクセス権限による保護をバイパスすることができてしまいます。

  対処予定:
	gfarm v2 では、スプールの構造上、この問題はありません。
	gfarm v1 での対処は未定です。

- グループ権限は実装されていません。

  対処予定:
	gfarm v2 の最初のリリースで対処します。
	gfarm v1 での対処は未定です。

- クライアントがクラッシュした場合に、一貫性が失われることがあります。

  gfarm v1 では、gfarm クライアントが直接メタデータを更新します。
  この結果、アプリケーションが処理途中でクラッシュしたり、あるいは
  kill(2) された場合、メタデータの状態に一貫性がなくなる可能性が
  あります。

  対処予定:
	gfarm v2 では、この問題はありません。
	gfarm v1 での対処は未定ですが、gfsck コマンドで一貫性のない
	メタデータを消去したり、あるいは Gfarm-FAQ にある通り、
	gfsplck で実ファイルを消去することはできます。

- ファイルシステムノードのスプール中にゴミが残ることがあります。

  gfarm v1 では、削除すべきレプリカやスプールディレクトリの情報を
  保持するメタデータが存在しません。
  このため、クライアントがクラッシュした場合のみならず、gfsd が
  一時的に落ちていたり、ネットワークトラブルがあった場合なども、
  スプール上にゴミファイルやゴミディレクトリが残ることがあります。

  対処予定:
	gfarm v2 の最初のリリースで対処します。
	gfarm v1 での対処は未定ですが、Gfarm-FAQ にある通り、
	gfsplck でゴミを消去することはできます。

- ファイルやディレクトリの名前に「:」が含まれていると正しく動作しない
  ことがあります。

  より正確には「:」の後が、数字 (ただし、2桁以上で、かつ0で始まる数字
  は除きます) か、あるいはアーキテクチャ名と同じ文字列であるような
  ファイル名やディレクトリ名を使うと正しく動作しないことがあります。
  これは、この形式のファイル名が、スプール中のファイルの実体と衝突する
  からです。

  対処予定:
	gfarm v2 では、スプールの構造上、この問題はありません。
	gfarm v1 での対処の予定はありません。

- gfarm 1.3 における、スケジューリング処理に誤りがあります。

  ファイルアクセスに関して、ローカルホストにレプリカがあれば優先する、
  また書き込みアクセスは、ディスク空き容量など、読み込みアクセスに
  ない考慮を行なうという仕様がありますが、gfarm 1.3 では、この処理に
  誤りがあり、ローカルホストが優先されず、また書き込みアクセスと
  読み込みアクセスの区別も行なわれません。

  対処予定:
	gfarm v1 の次のリリースで修正します。cvs 版では対処済みです。

- gfsd デーモンを立ち上げ直した場合、たとえばファイルシステムノードを
  リブートした場合、その gfsd と既に接続していたアプリケーションは、
  そのファイルシステムノードとの通信が行なえなくなります。

  これは、長時間続けて動作するデーモンプロセスやシェルなどで、特に
  問題となります。

  対処予定:
	gfarm v1 の次のリリースでは、新たにオープンし直したファイルに
	ついては、通信が回復するような対策を行ないます。cvs 版では対処
	済みです。
	オープンし続けているファイルに関する対処は未定です。

- global view に対する TRUNCATE モードでのオープンは、正しく動かない
  場合があります。

  あるセクションを一度だけ訪れる場合なら問題ありません。しかし、他の
  セクションに移動してから既に訪れたセクションに戻ってくると、その際に
  再度 TRUNCATE されてしまい、書き込み内容が失われてしまいます。

  対処予定:
	未定です。

- global view に対する追記 (APPEND) モードでのオープンは、現時点では
  サポートされていません。

  対処予定:
	未定です。

- global view でオープン後、chmod でオープン不能なモードに変更した場合、
  そのファイルに対する gfarm API 呼び出しに失敗することがあります。

  これは、global view に対する API 処理では、global view を構成する
  各セクション (フラグメント) をオープンし直すことがあるためです。
  なお、view の種類を指定しなかった場合のデフォルトは global view です
  ので、やはりこの問題が生じる可能性があります。

  対処予定:
	現時点では仕様上の制限事項であり、対処の予定はありません。
	単一のセクション (フラグメント) からなる global view に限れば、
	オープン直後に明示的に gfs_pio_set_view_global() を呼び出して
	おけば、この問題を避けることができます。

- global view に対する API 呼び出しのエラーの意味は不明確です。

  これは、複数のファイルフラグメントから構成されている global view に
  対する API 呼び出しは、これまでアクセスしていたフラグメントのクローズ、
  これからアクセスするフラグメントのオープン、さらに API で指定された
  処理の実行という、三つの操作の組合せになる場合があるからです。
  また、現在の実装では、このうち、これまでアクセスしていたフラグメントの
  クローズ処理でエラーが生じても、そのエラーは通知されないという問題が
  あります。

  対処予定:
	現時点では仕様上の制限事項であり、対処の予定はありません。
	ただし、これまでアクセスしていたフラグメントのクローズ処理で
	エラーが生じた場合に関しては、時期は未定なものの、エラーを
	通知するように直す予定です。

- 複数回 gfs_pio_set_view_*() API を実行した場合のエラーの意味は不明確です。

  二度目以降の gfs_pio_set_view_*() の呼び出しは、以前の view のクローズ
  処理と、新しい view のオープン処理を兼ねているので、クローズ時に生じた
  エラーか、オープン時に生じたエラーかを区別する方法はありません。

  対処予定:
	現時点では仕様上の制限事項であり、対処の予定はありません。
	エラーを厳密に検知したい場合には、1回のオープンに対して、
	gfs_pio_set_view_*() API の呼び出しを一度に限る必要があります。

- ファイルをオープン中に rename や unlink を行なうと、close 時に
  GFARM_ERR_NO_SUCH_OBJECT でエラーになります。

  システムコールフック経由の場合のエラーは ENOENT (No such file or directory)
  です。

  対処予定:
	gfarm v2 の最初のリリースで対処します。
	gfarm v1 での対処は未定です。

- chmod によって、実行ファイルを非実行ファイルに変更したり、あるいは
  非実行ファイルを実行ファイルに変更することが可能なのは、ファイルを
  構成するセクション数 (フラグメント数) が 1 つの場合だけです。

  セクション数 (フラグメント数) が 1 より大きい場合は、
  GFARM_ERR_OPERATION_NOT_PERMITTED でエラーになります。
  システムコールフック経由の場合のエラーは EPERM (Operation not permitted)
  です。

  対処予定:
	未定です。

- stat API は、ファイルをクローズするまで、正確なファイルサイズを返しません。

  section view (あるいは index view) であれば、gfs_pio_stat() API (フックの
  場合なら fstat() API) を利用すれば実際のファイルサイズを得ることができます。
  ただし、global view の場合には、この方法も使えません。

  対処予定:
	未定です。

- stat API の返す st_ino, st_nlink, st_group フィールドの値は、意味が
  ありません。

  st_ino フィールドは、同一プロセス中では、それぞれのファイルやディレクトリ
  は、ユニークな値をとります。しかし、異なるプロセス間ではたとえ同一の
  ファイルやディレクトリであっても、同一の値とはなりません。

  対処予定:
	gfarm v2 の最初のリリースで対処します。
	gfarm v1 での対処は未定です。

- 異なるプロセスが同時に同一のファイルやディレクトリ階層に対して処理を
  行なった場合、ファイルシステムの一貫性が失われる場合があります。

  異なるプロセスが同時に同一のファイルをオープンする場合に対しては、
  対策がとられていますので、実用上、特に問題はありません。

  しかし、ディレクトリや、多数のセクションからなるファイルの rename、
  あるいは chmod でファイルの実行属性を変更する場合などのように、複数の
  セクションに対して改名を伴う処理を行なう場合、この問題が生じる可能性が
  増えます。

  対処予定:
	gfarm v2 の最初のリリースで対処します。
	gfarm v1 での対処は未定です。

- gfarm ライブラリを既に利用開始しているプログラムが fork(2) した場合、
  gfarm ライブラリの API を呼び出すことができるのは、親プロセスだけです。

  対処予定:
	未定です。

- gfarm ライブラリは multithread safe ではありません。

  対処予定:
	gfarm v2 で対処します。
	gfarm v1 での対処は未定です。

- libgfarm は、単一プロセスが複数の異なるユーザ権限を使い分けるような
  アプリケーションからの利用を想定していません。

  setuid() や setgid() を用いるようなアプリケーションからの利用を
  想定していません。

  対処予定:
	未定です。

- ファイルシステムノードとの通信に用いる TCP コネクションキャッシュに
  上限がないため、gfarm ライブラリが、ファイルディスクリプタを使い尽くす
  可能性があります。

  多数のファイルシステムノードからなる gfarm 環境で、長時間続けて動作する
  デーモンプロセスやシェルを利用した場合、問題が生じる可能性があります。

  対処予定:
	gfarm v1 の次のリリースで修正します。

- ファイルシステムノードのスプールとしては、大文字小文字を区別する
  ファイルシステムのみをサポートしています。

  MacOS や cygwin のファイルシステムなどで、この問題が生じます。

  対処予定:
	現時点では仕様上の制限事項であり、対処の予定はありません。

- 設定可能な環境変数に関する参照マニュアルが存在しません。

  対処予定:
	未定です。


● gfarm コマンド群に関する問題点

- gfrcmd の -l オプションは実装されていません。

  対処予定:
	未定です。

- gfrep は、複製先ホストをスケジュールする際に、最低空き容量 (gfarm.conf
  の "minimum_free_disk_space") の検査を行ないますが、これは起動時に一度
  しか行なっていません。したがって、gfrep 実行中に最低空き容量を下回った
  場合、そのホストが選ばれ続けてしまうという問題があります。

  対処予定:
	未定です。

- gfrep は、複製元ホスト選ぶ基準として、起動時のロードアベレージの低い順
  を用いています。このため、gfrep コマンドを複数同時に並列で起動すると、
  複製元ホストの選択が偏ってしまい、そのホストの負荷だけが高くなってしま
  うという問題が生じることがあります。この問題は、同時に起動するのではな
  く、少しずつ起動時刻をずらすことで回避できます。
  なお、複製先ホストについては、可能な限りまんべんなく選択するように試み
  るので、この問題はありません。

  対処予定:
	未定です。

- gfmpirun は、MPICH/p4 にしか対応していません。また、全てのノードが
  同じアーキテクチャで、かつ同じスプールディレクトリの絶対パスが
  同一であると仮定しています。

  MPICH/p4 でしか動作しない理由は、現時点の gfmpirun の実装が、
  MPICH/p4 特有の -nolocal オプションを利用しているためです。  

  対処予定:
	未定です。

- 下記のコマンドに関する参照マニュアルが存在しません。

  config-agent, config-gfarm, config-gfsd, gfarm-pcp, gfarm-prun, 
  gfarm-ptool, gfarm.arch.guess, gfchmod, gfcombine, gfcombine_hook,
  gfcp, gfcp_hook, gfdump, gfrshl, gfsck, gfsplck, gfsshl, thput-gfpio

  対処予定:
	未定です。


● システムコールフックに関する問題点

  libgfs_hook に関する制限事項は、README.hook.ja に記述してあります。
  そちらを御覧ください。
  各問題点に関する対処の予定は、未定です。
